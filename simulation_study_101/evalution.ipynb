{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "import pandas as pd\n",
    "\n",
    "def load_simulation_results(study_number, N_C, d, n):\n",
    "    # Define the path to the results directory\n",
    "    base_dir = f\"/Users/jamiecuin/Documents/University/Imperial/MSc Statistics/Summer Project/EGM Changepoint Detection/Code/Simulation Studies/simulation_study_{study_number}/number_changepoints_{N_C}/number_nodes_{d}/number_samples_{n}/results/\"\n",
    "    \n",
    "    # Paths to the CSV files\n",
    "    sim_results_path = os.path.join(base_dir, \"simulation_results.csv\")\n",
    "    changepoints_path = os.path.join(base_dir, \"master_changepoint_locations.csv\")\n",
    "    \n",
    "    # Load the CSV files into DataFrames\n",
    "    sim_results_df = pd.read_csv(sim_results_path)\n",
    "    changepoints_df = pd.read_csv(changepoints_path)\n",
    "    \n",
    "    # Merge the two DataFrames on the \"simulation\" and \"permutation\" columns\n",
    "    merged_df = pd.merge(sim_results_df, changepoints_df, on=[\"simulation\", \"permutation\"], how=\"inner\")\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "study_number = 101\n",
    "N_C = 1\n",
    "d = 20\n",
    "n = 1000\n",
    "\n",
    "merged_results = load_simulation_results(study_number, N_C, d, n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_changepoint_evaluation(merged_df):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    merged_df['changepoint_indices'] = merged_df['changepoint_indices'].astype(str)\n",
    "    merged_df['predicted_changepoints'] = merged_df['predicted_changepoints'].astype(str)\n",
    "    \n",
    "    merged_df['true_changepoints_count'] = merged_df['changepoint_indices'].apply(lambda x: len(x.split(';')) if x != \"nan\" else 0)\n",
    "    \n",
    "    merged_df['predicted_changepoints_count'] = merged_df['predicted_changepoints'].apply(\n",
    "        lambda x: len(x.split(';')) if x != \"nan\" else 0\n",
    "    )\n",
    "    \n",
    "    merged_df['changepoints_diff'] = abs(merged_df['true_changepoints_count'] - merged_df['predicted_changepoints_count'])\n",
    "    \n",
    "    return merged_df\n",
    "\n",
    "evaluation_results = calculate_changepoint_evaluation(merged_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results['changepoints_diff'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_points_to_segments(change_points, n):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    segments = np.zeros(n, dtype=int)\n",
    "    for i, cp in enumerate(change_points):\n",
    "        segments[cp:] = i + 1\n",
    "    return segments\n",
    "\n",
    "def calculate_ari(estimated_cps, true_cps, n):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    est_segments = change_points_to_segments(estimated_cps, n)\n",
    "    true_segments = change_points_to_segments(true_cps, n)\n",
    "    return adjusted_rand_score(true_segments, est_segments)\n",
    "\n",
    "def calculate_average_ari(merged_df, n):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    ari_scores = []\n",
    "    \n",
    "    for _, row in merged_df.iterrows():\n",
    "        # Convert the true changepoints from strings to lists of integers\n",
    "        true_cps = [int(x) for x in row['changepoint_indices'].split(';') if x and x != 'nan']\n",
    "        \n",
    "        # Handle NaN values or 'nan' strings in predicted changepoints\n",
    "        if pd.isna(row['predicted_changepoints']) or row['predicted_changepoints'] == 'nan':\n",
    "            estimated_cps = []\n",
    "        else:\n",
    "            estimated_cps = [int(float(x)) for x in row['predicted_changepoints'].split(';') if x and x != 'nan']\n",
    "        \n",
    "        # Calculate ARI for the current simulation\n",
    "        ari = calculate_ari(estimated_cps, true_cps, n)\n",
    "        ari_scores.append(ari)\n",
    "    \n",
    "    # Calculate and return the average ARI\n",
    "    average_ari = np.mean(ari_scores)\n",
    "    return average_ari\n",
    "\n",
    "average_ari = calculate_average_ari(merged_results, n)\n",
    "\n",
    "average_ari\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_points_to_segments(change_points, n):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    segments = np.zeros(n, dtype=int)\n",
    "    for i, cp in enumerate(change_points):\n",
    "        segments[cp:] = i + 1\n",
    "    return segments\n",
    "\n",
    "def calculate_ari(estimated_cps, true_cps, n):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    est_segments = change_points_to_segments(estimated_cps, n)\n",
    "    true_segments = change_points_to_segments(true_cps, n)\n",
    "    return adjusted_rand_score(true_segments, est_segments)\n",
    "\n",
    "def calculate_ari_for_correct_count(merged_df, n):\n",
    "    \"\"\"\n",
    "    TODO\n",
    "    \"\"\"\n",
    "    ari_scores = []\n",
    "    \n",
    "    for _, row in merged_df.iterrows():\n",
    "        true_cps = [int(x) for x in row['changepoint_indices'].split(';') if x and x != 'nan']\n",
    "        \n",
    "        if pd.isna(row['predicted_changepoints']) or row['predicted_changepoints'] == 'nan':\n",
    "            estimated_cps = []\n",
    "        else:\n",
    "            estimated_cps = [int(float(x)) for x in row['predicted_changepoints'].split(';') if x and x != 'nan']\n",
    "        \n",
    "        if len(estimated_cps) == len(true_cps):\n",
    "            ari = calculate_ari(estimated_cps, true_cps, n)\n",
    "            ari_scores.append(ari)\n",
    "    \n",
    "    if ari_scores: \n",
    "        average_ari = np.mean(ari_scores)\n",
    "    else:\n",
    "        average_ari = np.nan  # Handle cases where no matches were found\n",
    "    \n",
    "    return average_ari\n",
    "\n",
    "average_ari_for_correct_count = calculate_ari_for_correct_count(merged_results, n)\n",
    "\n",
    "average_ari_for_correct_count\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
